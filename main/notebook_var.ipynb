{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/philippratz/Documents/Uni/PhD/UQAM/research/ml_time_series/code/new_push/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('./data/prepared_stocks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = df_.head(2992-1000)\n",
    "test_ = df_.tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(preds, target, quantiles):\n",
    "    assert not target.requires_grad\n",
    "    assert preds.size(0) == target.size(0)\n",
    "    losses = []\n",
    "    i=0\n",
    "    q=0.99\n",
    "    errors = target - preds\n",
    "    losses.append(torch.max((q - 1) * errors, q * errors).unsqueeze(1))\n",
    "    loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMLP(nn.Module):\n",
    "    def __init__(self, arch,\n",
    "                 input_size=2,\n",
    "                 output_size = 1,\n",
    "                 dropout=0.1, \n",
    "                 output_function=''):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self._set_arch(arch, input_size)\n",
    "        self.output_function = output_function\n",
    "        \n",
    "    def _set_arch(self, arch, input_size):\n",
    "        current_size = input_size\n",
    "        for lay_size in arch:\n",
    "            self.layers.append(nn.Linear(current_size, lay_size))\n",
    "            current_size = lay_size\n",
    "            \n",
    "        self.final_layer = nn.Linear(current_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for lay_ in self.layers:\n",
    "            x = F.relu(lay_(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.final_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_ = BaseMLP([4,4,4], input_size=2, output_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = train_.loc[:,['chf']]\n",
    "y_2 = train_.loc[:,['gold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_.loc[:, ['lag_1_chf', 'lag_1_gold']]\n",
    "X_test = test_.loc[:, ['lag_1_chf', 'lag_1_gold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TabularDataSet(Dataset):\n",
    "    def __init__(self, X, y_1, y_2):\n",
    "        self.X = X.copy()\n",
    "        self.y1 = y_1\n",
    "        self.y2 = y_2\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y1[idx], self.y2[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = TabularDataSet(X_train.to_numpy(),\n",
    "                            np.float32(y_1),\n",
    "                            np.float32(y_2))\n",
    "    \n",
    "trainloader = DataLoader(data_train, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_ = optim.Adam(mlp_.parameters(),\n",
    "                        lr=0.05)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for i, (x_train, y1, y2) in enumerate(trainloader):\n",
    "        optimizer_.zero_grad()\n",
    "\n",
    "        y_pred_batch = mlp_(x_train.float())\n",
    "\n",
    "        loss_1 = quantile_loss(y_pred_batch[:,0], y1.squeeze(), 0.99)\n",
    "        loss_2 = quantile_loss(y_pred_batch[:,1], y2.squeeze(), 0.99)\n",
    "\n",
    "        total_loss = loss_1 + loss_2\n",
    "        total_loss.backward()\n",
    "        optimizer_.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preeds_ = mlp_(torch.from_numpy(np.float32(X_test.to_numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0365, 0.0440],\n",
       "        [0.0365, 0.0440],\n",
       "        [0.0365, 0.0440],\n",
       "        ...,\n",
       "        [0.0365, 0.0440],\n",
       "        [0.0365, 0.0440],\n",
       "        [0.0365, 0.0440]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preeds_[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_rlp",
   "language": "python",
   "name": "env_rlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
