{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/philippratz/Documents/Uni/PhD/UQAM/courses/RL/mcgill_precup/project/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.environment.simple_environment import SimpleEconEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBaseMLP\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      2\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, arch,\n\u001b[1;32m      3\u001b[0m                  input_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m      4\u001b[0m                  output_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m                  dropout\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, \n\u001b[1;32m      6\u001b[0m                  output_function\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      7\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class BaseMLP(nn.Module):\n",
    "    def __init__(self, arch,\n",
    "                 input_size=2,\n",
    "                 output_size = 1,\n",
    "                 dropout=0.1, \n",
    "                 output_function=None):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self._set_arch(arch, input_size)\n",
    "        self.output_function = output_function\n",
    "        \n",
    "    def _set_arch(self, arch, input_size):\n",
    "        current_size = input_size\n",
    "        for lay_size in arch:\n",
    "            self.layers.append(nn.Linear(current_size, lay_size))\n",
    "            current_size = lay_size\n",
    "            \n",
    "        self.final_layer = nn.Linear(current_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for lay_ in self.layers:\n",
    "            x = F.relu(lay_(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.final_layer(x)\n",
    "\n",
    "        if self.output_function is not None:\n",
    "            x = self.output_function(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "def init_weights(lay):\n",
    "    if isinstance(lay, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(lay.weight)\n",
    "        lay.bias.data.fill_(1.0)\n",
    "    \n",
    "\n",
    "def train_model(replay_buffer,\n",
    "                model,\n",
    "                target_model,\n",
    "                optimizer,\n",
    "                batch_size=128, \n",
    "                gamma=0.99):\n",
    "\n",
    "    trans_sample = replay_buffer.sample(batch_size)\n",
    "    batch = Transition(*zip(*trans_sample))\n",
    "\n",
    "    sample_state = torch.cat(batch.state)\n",
    "    sample_reward = torch.cat(batch.reward)\n",
    "    sample_action = torch.cat(batch.action)\n",
    "    sample_next_state = torch.cat(batch.next_state)\n",
    "\n",
    "    # cast to avoid issues with torch\n",
    "    sample_state = sample_state.type(torch.FloatTensor)\n",
    "    sample_next_state = sample_next_state.type(torch.FloatTensor)\n",
    "\n",
    "    q_values_hat = model(sample_state).gather(1,sample_action)\n",
    "\n",
    "    # No grad here as we do not optimize target net\n",
    "    target_model.eval()\n",
    "    with torch.no_grad():\n",
    "        next_q_val, _ = target_model(sample_next_state).max(1)\n",
    "    target_model.train()\n",
    "    \n",
    "    target_value = sample_reward.squeeze() + gamma* next_q_val\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(q_values_hat.squeeze(), target_value)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(model.parameters(), 100)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def soft_update_nets(model, target_model, tau):\n",
    "    target_states = target_model.state_dict()\n",
    "    model_states = model.state_dict()\n",
    "\n",
    "    for key in model_states:\n",
    "        target_states[key] = tau*model_states[key] + (1-tau)*target_states[key]\n",
    "    target_model.load_state_dict(target_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8255],\n",
       "        [0.9581],\n",
       "        [0.7071],\n",
       "        [0.8343],\n",
       "        [0.8472],\n",
       "        [0.8622],\n",
       "        [0.5387],\n",
       "        [0.7423],\n",
       "        [0.8512],\n",
       "        [0.7458]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_1(sample_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPG_Actor:\n",
    "    def __init__(self,\n",
    "                 all_models,\n",
    "                 memory_buffer,\n",
    "                 lr=0.05,\n",
    "                 lr_critic=0.0125,\n",
    "                 tau=0.005, \n",
    "                 batch_size=64,\n",
    "                 gamma=0.95):\n",
    "        \n",
    "        self.critic = all_models['critic']\n",
    "        self.critic.apply(init_weights)\n",
    "        self.target_critic = all_models['critic']\n",
    "\n",
    "        self.actor = all_models['actor']\n",
    "        self.actor.apply(init_weights)\n",
    "        self.target_actor = all_models['actor']\n",
    "\n",
    "        for target_param, param in zip(self.target_critic.parameters(),\n",
    "                                       self.critic.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "        for target_param, param in zip(self.target_actor.parameters(),\n",
    "                                       self.actor.parameters()):\n",
    "            target_param.data.copy_(param.data)\n",
    "\n",
    "        self.actor_optimizer = optim.Adam(\n",
    "            self.actor.parameters(),\n",
    "            lr=lr)\n",
    "\n",
    "        self.critic_optimizer = optim.Adam(\n",
    "            self.critic.parameters(), \n",
    "            lr=lr_critic)\n",
    "\n",
    "        self.memory = memory_buffer\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = np.float32(gamma)\n",
    "        self.tau = tau\n",
    "\n",
    "        \n",
    "    def init_weights(self, lay):\n",
    "        if isinstance(lay, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(lay.weight)\n",
    "            lay.bias.data.fill_(1.0)\n",
    "\n",
    "    def sample_action(self, state):\n",
    "        action = self.actor(state)\n",
    "        return action.detach().numpy()\n",
    "    \n",
    "    def soft_update_nets(self, model, target_model, tau):\n",
    "            target_states = target_model.state_dict()\n",
    "            model_states = model.state_dict()\n",
    "\n",
    "            for key in model_states:\n",
    "                target_states[key] = tau*model_states[key] + (1-tau)*target_states[key]\n",
    "            target_model.load_state_dict(target_states)\n",
    "    \n",
    "    def update(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        trans_sample = self.memory.sample(self.batch_size)\n",
    "        batch = Transition(*zip(*trans_sample))\n",
    "\n",
    "        state = torch.cat(batch.state)\n",
    "        reward = torch.cat(batch.reward)\n",
    "        action = torch.cat(batch.action)\n",
    "        next_state = torch.cat(batch.next_state)\n",
    "\n",
    "        # cast to avoid issues with torch\n",
    "        action = action.type(torch.float32)\n",
    "        state = state.type(torch.float32)\n",
    "        next_state = next_state.type(torch.float32)\n",
    "\n",
    "        target_action = self.target_actor(next_state)\n",
    "        target_critic_values = self.target_critic(torch.cat((next_state, target_action), 1))\n",
    "\n",
    "        critic_value = self.critic(torch.cat((next_state, action), 1))\n",
    "        target = (reward.reshape(-1,) + self.gamma * target_critic_values.reshape(-1,)).type(torch.float32).reshape(-1,1)\n",
    "\n",
    "        # print(reward)\n",
    "        # print(target_critic_values)\n",
    "\n",
    "        # print(target)\n",
    "        # print(reward.shape)\n",
    "        # print(self.gamma)\n",
    "        # print(target_critic_values.shape)\n",
    "\n",
    "        # print(reward.type)\n",
    "        # print(target_critic_values.type)\n",
    "\n",
    "\n",
    "        critic_loss_fct = nn.MSELoss()\n",
    "        critic_loss = critic_loss_fct(critic_value, target)\n",
    "\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "\n",
    "        # Now for the others\n",
    "        policy_actions = self.actor(state)\n",
    "        actor_loss = -self.critic(torch.cat((state, policy_actions), 1))\n",
    "        actor_loss = actor_loss.mean()\n",
    "\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()\n",
    "\n",
    "        # Soft updates\n",
    "        self.soft_update_nets(self.critic, self.target_critic, self.tau)\n",
    "        self.soft_update_nets(self.actor, self.target_actor, self.tau)\n",
    "\n",
    "\n",
    "        # for target_param, param in zip(self.target_critic.parameters(),\n",
    "        #                                self.critic.parameters()):\n",
    "        #     target_param.data.copy_(\n",
    "        #         target_param.data * (1.0 - self.tau) +\n",
    "        #         param.data * self.tau\n",
    "        #     )\n",
    "        # for target_param, param in zip(self.target_actor.parameters(),\n",
    "        #                                self.actor.parameters()):\n",
    "        #     target_param.data.copy_(\n",
    "        #         target_param.data * (1.0 - self.tau) +\n",
    "        #         param.data * self.tau\n",
    "        #     )\n",
    "\n",
    "\n",
    "        # actor_loss = self.critic(state, self.actor(state))\n",
    "        # actor_loss = -actor_loss.mean()\n",
    "\n",
    "        # next_action = self.target_actor(next_state)\n",
    "        # target_value = self.target_critic(next_state, next_action.detach())\n",
    "\n",
    "        # # 这里的expected_value就是伪代码中间的y_i  \n",
    "        \n",
    "        # expected_value = (reward.squeeze() + self.gamma * target_value.squeeze()).reshape(-1,1)\n",
    "        # expected_value = torch.clamp(expected_value, 0, 15)\n",
    "        \n",
    "        # actual_value = self.critic(state, action)\n",
    "        # critic_loss_fct = nn.SmoothL1Loss()\n",
    "        \n",
    "        # actual_value = actual_value.type(torch.float32)\n",
    "        # expected_value = expected_value.type(torch.float32)\n",
    "\n",
    "        # critic_loss = critic_loss_fct(actual_value, expected_value.detach())\n",
    "        # critic_loss = critic_loss.type(torch.float32)\n",
    "        \n",
    "        # self.actor_optimizer.zero_grad()\n",
    "        # actor_loss.backward()\n",
    "        # self.actor_optimizer.step()\n",
    "        # self.critic_optimizer.zero_grad()\n",
    "        # critic_loss.backward()\n",
    "        # self.critic_optimizer.step()\n",
    "        # for target_param, param in zip(self.target_critic.parameters(),\n",
    "        #                                self.critic.parameters()):\n",
    "        #     target_param.data.copy_(\n",
    "        #         target_param.data * (1.0 - self.tau) +\n",
    "        #         param.data * self.tau\n",
    "        #     )\n",
    "        # for target_param, param in zip(self.target_actor.parameters(),\n",
    "        #                                self.actor.parameters()):\n",
    "        #     target_param.data.copy_(\n",
    "        #         target_param.data * (1.0 - self.tau) +\n",
    "        #         param.data * self.tau\n",
    "        #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseMLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 arch,\n",
    "                 input_size=2,\n",
    "                 output_size = 1,\n",
    "                 dropout=0.1, \n",
    "                 positive=False):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.positive = positive\n",
    "        self._set_arch(arch, input_size)\n",
    "        \n",
    "    def _set_arch(self, arch, input_size):\n",
    "        current_size = input_size\n",
    "        for lay_size in arch:\n",
    "            self.layers.append(nn.Linear(current_size, lay_size))\n",
    "            current_size = lay_size\n",
    "            \n",
    "        self.final_layer = nn.Linear(current_size, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for lay_ in self.layers:\n",
    "            x = F.relu(lay_(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.final_layer(x)\n",
    "\n",
    "\n",
    "\n",
    "        # if self.positive:\n",
    "        #     x = F.relu(x)        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agents, num_trials):\n",
    "    print(\"开始训练！\")\n",
    "    ou_noise = OUNoise()  # 动作噪声\n",
    "    ou_noise_1 = OUNoise()\n",
    "    rewards_1 = [] # 记录所有回合的奖励\n",
    "    rewards_2 = []\n",
    "    ou_noise.reset()\n",
    "    ou_noise_1.reset()\n",
    "\n",
    "    state = torch.tensor(np.random.uniform(low=1.47,\n",
    "                                           high=2,\n",
    "                                           size=(2,)),\n",
    "                            dtype=torch.float32).reshape(1,2)\n",
    "\n",
    "    for i_step in range(num_trials):\n",
    "        # if i_step % 10000 == 0:\n",
    "        #     try:\n",
    "        #         print(action_1, action_2)\n",
    "        #     except UnboundLocalError:\n",
    "        #         pass            \n",
    "        \n",
    "        # action_1 = agents[0].sample_action(state)\n",
    "        # action_1 = action_1[0][0]\n",
    "        # action_1 = action_1 + np.random.normal(scale=0.2)\n",
    "        \n",
    "        # #action_1 = np.max([1.47,action_1])\n",
    "\n",
    "        # action_2 = agents[1].sample_action(state)\n",
    "        # #action_2 = action_2 + np.random.gamma(shape=0.5*np.exp(-i_step*0.0001))#ou_noise.get_action(action_1, i_step+1) \n",
    "        # action_2 = action_2[0][0]\n",
    "        # action_2 = action_2 + np.random.normal(scale=0.2)\n",
    "        # #action_2 = np.max([1.47,action_2])\n",
    "\n",
    "        # # print(action_1)\n",
    "        # # print(action_2)\n",
    "        # if np.isnan(action_1):\n",
    "        #     print(action_1)\n",
    "        #     print(state)\n",
    "\n",
    "        # price_tensor = torch.tensor([action_1, action_2],\n",
    "        #                             dtype=torch.float32).reshape(1,-1)\n",
    "\n",
    "        # d1, d2 = env(action_1, action_2)\n",
    "        \n",
    "        # reward_a1 = torch.tensor((action_1 - 1)*d1).reshape(1,-1)\n",
    "        # reward_a2 = torch.tensor((action_2 - 1)*d2).reshape(1,-1)\n",
    "\n",
    "        # # print(reward_a1)\n",
    "        # # print(reward_a2)\n",
    "\n",
    "        # next_state = price_tensor\n",
    "\n",
    "        # agents[0].memory.push(state, torch.tensor(action_1, dtype=torch.float32).reshape(1,1),\n",
    "        #                       next_state, reward_a1)\n",
    "        # agents[1].memory.push(state, torch.tensor(action_2, dtype=torch.float32).reshape(1,1),\n",
    "        #                       next_state, reward_a2)\n",
    "\n",
    "        agents[0].update()\n",
    "        agents[1].update()\n",
    "\n",
    "        \n",
    "\n",
    "        # state = next_state\n",
    "\n",
    "        # rewards_1.append(float(reward_a1.detach().numpy()))\n",
    "        # rewards_2.append(float(reward_a2.detach().numpy()))\n",
    "\n",
    "    return rewards_1, rewards_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/buffers/buf_1.pkl', 'rb') as con_:\n",
    "    buf_1 = pickle.load(con_)\n",
    "\n",
    "with open('data/buffers/buf_2.pkl', 'rb') as con_:\n",
    "    buf_2  = pickle.load(con_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = {'actor':  BaseMLP([15,15,15], positive=True), \n",
    "            'critic': BaseMLP([15,15,15], input_size=3, positive=True)}\n",
    "\n",
    "models_2 = {'actor':  BaseMLP([15,15,15], positive=True), \n",
    "            'critic': BaseMLP([15,15,15], input_size=3, positive=True)}\n",
    "\n",
    "#replay_1 = ReplayMemory(1000)\n",
    "actor_1 = DDPG_Actor(models_1, buf_1)\n",
    "\n",
    "#replay_2 = ReplayMemory(1000)\n",
    "actor_2 = DDPG_Actor(models_2, buf_2)\n",
    "\n",
    "envir = SimpleEconEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_1 = BaseMLP([15,15,15], positive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseMLP(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=2, out_features=15, bias=True)\n",
       "    (1-2): 2 x Linear(in_features=15, out_features=15, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (final_layer): Linear(in_features=15, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_1.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8255],\n",
      "        [0.9581],\n",
      "        [0.7071],\n",
      "        [0.8343],\n",
      "        [0.8472],\n",
      "        [0.8622],\n",
      "        [0.5387],\n",
      "        [0.7423],\n",
      "        [0.8512],\n",
      "        [0.7458]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    mod_1.eval()\n",
    "    print(mod_1(sample_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练！\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(envir, [actor_1, actor_2], 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = buf_1.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Transition(*zip(*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = envir(300.3666, 2.51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[347.2950],\n",
      "        [272.0719],\n",
      "        [250.3665],\n",
      "        [325.9579],\n",
      "        [347.2950],\n",
      "        [347.2950],\n",
      "        [347.2950],\n",
      "        [305.2732],\n",
      "        [240.9516],\n",
      "        [347.2950],\n",
      "        [307.3696],\n",
      "        [347.2950],\n",
      "        [292.3883],\n",
      "        [328.6905],\n",
      "        [245.4599],\n",
      "        [347.2950],\n",
      "        [290.8663],\n",
      "        [347.2950],\n",
      "        [305.2732],\n",
      "        [347.2950],\n",
      "        [292.3883],\n",
      "        [347.2950],\n",
      "        [290.8663],\n",
      "        [347.2950],\n",
      "        [347.2950],\n",
      "        [347.2950],\n",
      "        [ 20.7487],\n",
      "        [347.2950],\n",
      "        [347.2950],\n",
      "        [279.0295]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(actor_1.target_actor(torch.cat(batch.state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_1.actor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练！\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[554], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m all_b \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     a, b \u001b[39m=\u001b[39m train(envir, [actor_1, actor_2], \u001b[39m50000\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m     all_a\u001b[39m.\u001b[39mappend(a)\n\u001b[1;32m      6\u001b[0m     all_b\u001b[39m.\u001b[39mappend(b)\n",
      "Cell \u001b[0;32mIn[551], line 58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env, agents, num_trials)\u001b[0m\n\u001b[1;32m     10\u001b[0m state \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(low\u001b[39m=\u001b[39m\u001b[39m1.47\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                        high\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                        size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,)),\n\u001b[1;32m     13\u001b[0m                         dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i_step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_trials):\n\u001b[1;32m     16\u001b[0m     \u001b[39m# if i_step % 10000 == 0:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m#     try:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39m# agents[1].memory.push(state, torch.tensor(action_2, dtype=torch.float32).reshape(1,1),\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[39m#                       next_state, reward_a2)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m     agents[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mupdate()\n\u001b[1;32m     59\u001b[0m     agents[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m     61\u001b[0m     \u001b[39m# state = next_state\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m     \u001b[39m# rewards_1.append(float(reward_a1.detach().numpy()))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# rewards_2.append(float(reward_a2.detach().numpy()))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[523], line 96\u001b[0m, in \u001b[0;36mDDPG_Actor.update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m critic_loss \u001b[39m=\u001b[39m critic_loss_fct(critic_value, target)\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 96\u001b[0m critic_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     99\u001b[0m \u001b[39m# Now for the others\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Uni/PhD/UQAM/courses/RL/mcgill_precup/project/env_rlp/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Uni/PhD/UQAM/courses/RL/mcgill_precup/project/env_rlp/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_a = []\n",
    "all_b = []\n",
    "for k in range(5):\n",
    "    a, b = train(envir, [actor_1, actor_2], 50000)\n",
    "    all_a.append(a)\n",
    "    all_b.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x299767610>]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(all_a).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, n_states, n_actions=1, hidden_dim = 20, init_w=0.01):\n",
    "        super(Actor, self).__init__()  \n",
    "        self.linear1 = nn.Linear(n_states, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, n_actions)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return x\n",
    "        \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, n_states, n_actions=1, hidden_dim=20, init_w=0.01):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(n_states + n_actions, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "        # 随机初始化为较小的值\n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        # 按维数1拼接\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise(object):\n",
    "    '''Ornstein–Uhlenbeck噪声\n",
    "    '''\n",
    "    def __init__(self, action_space=1, mu=0,\n",
    "                 theta=0.15, max_sigma=0.3, min_sigma=0.3, decay_period=100000):\n",
    "        self.mu           = mu # OU噪声的参数\n",
    "        self.theta        = theta # OU噪声的参数\n",
    "        self.sigma        = max_sigma # OU噪声的参数\n",
    "        self.max_sigma    = max_sigma\n",
    "        self.min_sigma    = min_sigma\n",
    "        self.decay_period = decay_period\n",
    "        self.n_actions   = action_space\n",
    "        self.low          = 1\n",
    "        self.high         = 4\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.obs = np.ones(self.n_actions) * self.mu\n",
    "    def evolve_obs(self):\n",
    "        x  = self.obs\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.n_actions)\n",
    "        self.obs = x + dx\n",
    "        return self.obs\n",
    "    def get_action(self, action, t=0):\n",
    "        ou_obs = self.evolve_obs()\n",
    "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period) # sigma会逐渐衰减\n",
    "        return np.clip(action + ou_obs, self.low, self.high) # 动作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agents, num_trials):\n",
    "    print(\"开始训练！\")\n",
    "    ou_noise = OUNoise()  # 动作噪声\n",
    "    ou_noise_1 = OUNoise()\n",
    "    rewards_1 = [] # 记录所有回合的奖励\n",
    "    rewards_2 = []\n",
    "    ou_noise.reset()\n",
    "    ou_noise_1.reset()\n",
    "\n",
    "    state = torch.tensor(np.random.uniform(low=1.47,\n",
    "                                           high=2,\n",
    "                                           size=(2,)),\n",
    "                            dtype=torch.float32).reshape(1,2)\n",
    "\n",
    "    for i_step in range(num_trials):\n",
    "        if i_step % 1000 == 0:\n",
    "            print(i_step)\n",
    "            try:\n",
    "                print(action_1, action_2)\n",
    "            except UnboundLocalError:\n",
    "                pass\n",
    "\n",
    "        action_1 = agents[0].sample_action(state)\n",
    "        #action_1 = action_1 + np.random.gamma(shape=0.5*np.exp(-i_step*0.0001))#ou_noise.get_action(action_1, i_step+1) \n",
    "        action_1 = action_1[0][0]\n",
    "        \n",
    "        #action_1 = np.max([1.47,action_1])\n",
    "\n",
    "        action_2 = agents[1].sample_action(state)\n",
    "        #action_2 = action_2 + np.random.gamma(shape=0.5*np.exp(-i_step*0.0001))#ou_noise.get_action(action_1, i_step+1) \n",
    "        action_2 = action_2[0][0]\n",
    "        #action_2 = np.max([1.47,action_2])\n",
    "\n",
    "        # print(action_1)\n",
    "        # print(action_2)\n",
    "\n",
    "        price_tensor = torch.tensor([action_1, action_2],\n",
    "                                    dtype=torch.float32).reshape(1,-1)\n",
    "\n",
    "        d1, d2 = env(action_1, action_2)\n",
    "        \n",
    "        reward_a1 = torch.tensor((action_1 - 1)*d1).reshape(1,-1)\n",
    "        reward_a2 = torch.tensor((action_2 - 1)*d2).reshape(1,-1)\n",
    "\n",
    "        # print(reward_a1)\n",
    "        # print(reward_a2)\n",
    "\n",
    "        next_state = price_tensor\n",
    "\n",
    "        agents[0].memory.push(state, torch.tensor(action_1, dtype=torch.float32).reshape(1,1),\n",
    "                              next_state, reward_a1)\n",
    "        agents[1].memory.push(state, torch.tensor(action_2, dtype=torch.float32).reshape(1,1),\n",
    "                              next_state, reward_a2)\n",
    "\n",
    "        agents[0].update()\n",
    "        agents[1].update()\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        rewards_1.append(float(reward_a1.detach().numpy()))\n",
    "        rewards_2.append(float(reward_a2.detach().numpy()))\n",
    "\n",
    "    return rewards_1, rewards_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agents, num_trials):\n",
    "    print(\"开始训练！\")\n",
    "    ou_noise = OUNoise()  # 动作噪声\n",
    "    ou_noise_1 = OUNoise()\n",
    "    rewards_1 = [] # 记录所有回合的奖励\n",
    "    rewards_2 = []\n",
    "    ou_noise.reset()\n",
    "    ou_noise_1.reset()\n",
    "\n",
    "    state = torch.tensor(np.random.uniform(low=1.47,\n",
    "                                           high=2,\n",
    "                                           size=(2,)),\n",
    "                            dtype=torch.float32).reshape(1,2)\n",
    "\n",
    "    for i_step in range(num_trials):\n",
    "        if i_step % 1000 == 0:\n",
    "            print(i_step)\n",
    "            try:\n",
    "                print(action_1, action_2)\n",
    "            except UnboundLocalError:\n",
    "                pass\n",
    "\n",
    "        action_1 = agents[0].sample_action(state)\n",
    "        action_1 = action_1 + np.random.gamma(shape=0.5*np.exp(-i_step*0.0001))#ou_noise.get_action(action_1, i_step+1) \n",
    "        action_1 = action_1[0][0]\n",
    "        \n",
    "        #action_1 = np.max([1.47,action_1])\n",
    "\n",
    "        action_2 = agents[1].sample_action(state)\n",
    "        action_2 = action_2 + np.random.gamma(shape=0.5*np.exp(-i_step*0.0001))#ou_noise.get_action(action_1, i_step+1) \n",
    "        action_2 = action_2[0][0]\n",
    "        #action_2 = np.max([1.47,action_2])\n",
    "\n",
    "        # print(action_1)\n",
    "        # print(action_2)\n",
    "\n",
    "        price_tensor = torch.tensor([action_1, action_2],\n",
    "                                    dtype=torch.float32).reshape(1,-1)\n",
    "\n",
    "        d1, d2 = env(action_1, action_2)\n",
    "        \n",
    "        reward_a1 = torch.tensor((action_1 - 1)*d1).reshape(1,-1)\n",
    "        reward_a2 = torch.tensor((action_2 - 1)*d2).reshape(1,-1)\n",
    "\n",
    "        # print(reward_a1)\n",
    "        # print(reward_a2)\n",
    "\n",
    "        next_state = price_tensor\n",
    "\n",
    "        agents[0].memory.push(state, torch.tensor(action_1, dtype=torch.float32).reshape(1,1),\n",
    "                              next_state, reward_a1)\n",
    "        agents[1].memory.push(state, torch.tensor(action_2, dtype=torch.float32).reshape(1,1),\n",
    "                              next_state, reward_a2)\n",
    "\n",
    "        agents[0].update()\n",
    "        agents[1].update()\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        rewards_1.append(float(reward_a1.detach().numpy()))\n",
    "        rewards_2.append(float(reward_a2.detach().numpy()))\n",
    "\n",
    "    return rewards_1, rewards_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_1 = {'actor':  Actor(2), \n",
    "            'critic': Critic(2)}\n",
    "\n",
    "models_2 = {'actor':  Actor(2), \n",
    "            'critic': Critic(2)}\n",
    "\n",
    "replay_1 = ReplayMemory(1000)\n",
    "actor_1 = DDPG_Actor(models_1, replay_1)\n",
    "\n",
    "replay_2 = ReplayMemory(1000)\n",
    "actor_2 = DDPG_Actor(models_2, replay_2)\n",
    "\n",
    "envir = SimpleEconEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练！\n",
      "0\n",
      "1000\n",
      "1.0534246 1.0110514\n",
      "2000\n",
      "1.0257945 1.1830912\n",
      "3000\n",
      "1.0064166 1.0001221\n",
      "4000\n",
      "1.0072434 1.781799\n",
      "5000\n",
      "1.7864602 1.0022182\n",
      "6000\n",
      "1.83484 1.1512321\n",
      "7000\n",
      "1.1235956 1.0002\n",
      "8000\n",
      "1.0268321 1.1299069\n",
      "9000\n",
      "1.8006325 1.0055082\n",
      "10000\n",
      "1.0000006 1.0041665\n",
      "11000\n",
      "1.004067 1.001761\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[363], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m all_b \u001b[39m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     a, b \u001b[39m=\u001b[39m train(envir, [actor_1, actor_2], \u001b[39m20000\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m     all_a\u001b[39m.\u001b[39mappend(a)\n\u001b[1;32m      6\u001b[0m     all_b\u001b[39m.\u001b[39mappend(b)\n",
      "Cell \u001b[0;32mIn[361], line 55\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(env, agents, num_trials)\u001b[0m\n\u001b[1;32m     50\u001b[0m agents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mpush(state, torch\u001b[39m.\u001b[39mtensor(action_1, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),\n\u001b[1;32m     51\u001b[0m                       next_state, reward_a1)\n\u001b[1;32m     52\u001b[0m agents[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mpush(state, torch\u001b[39m.\u001b[39mtensor(action_2, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m),\n\u001b[1;32m     53\u001b[0m                       next_state, reward_a2)\n\u001b[0;32m---> 55\u001b[0m agents[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mupdate()\n\u001b[1;32m     56\u001b[0m agents[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m     58\u001b[0m state \u001b[39m=\u001b[39m next_state\n",
      "Cell \u001b[0;32mIn[354], line 50\u001b[0m, in \u001b[0;36mDDPG_Actor.update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m state \u001b[39m=\u001b[39m state\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     48\u001b[0m next_state \u001b[39m=\u001b[39m next_state\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 50\u001b[0m actor_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic(state, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor(state))\n\u001b[1;32m     51\u001b[0m actor_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mactor_loss\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     53\u001b[0m next_action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_actor(next_state)\n",
      "File \u001b[0;32m~/Documents/Uni/PhD/UQAM/courses/RL/mcgill_precup/project/env_rlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[355], line 17\u001b[0m, in \u001b[0;36mActor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(x))\n\u001b[1;32m     16\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(x))\n\u001b[0;32m---> 17\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinear3(x))\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Uni/PhD/UQAM/courses/RL/mcgill_precup/project/env_rlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Uni/PhD/UQAM/courses/RL/mcgill_precup/project/env_rlp/lib/python3.10/site-packages/torch/nn/modules/linear.py:113\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m         bound \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(fan_in) \u001b[39mif\u001b[39;00m fan_in \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    111\u001b[0m         init\u001b[39m.\u001b[39muniform_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39m-\u001b[39mbound, bound)\n\u001b[0;32m--> 113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextra_repr\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_a = []\n",
    "all_b = []\n",
    "for k in range(5):\n",
    "    a, b = train(envir, [actor_1, actor_2], 20000)\n",
    "    all_a.append(a)\n",
    "    all_b.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291defee0>]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(all_b).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_noise(self, x, theta=THETA, mu=0, dt=DT, std=0.2):\n",
    "        \"\"\"\n",
    "        Ornstein–Uhlenbeck process\n",
    "        \"\"\"\n",
    "        return x + theta * (mu-x) * dt + std * np.sqrt(dt) * np.random.normal(size=self.actions_dim)\n",
    "\n",
    "def get_action(self, observation, noise, evaluation=False):\n",
    "    state = tf.convert_to_tensor([observation], dtype=tf.float32)\n",
    "    actions = self.actor(state)\n",
    "    if not evaluation:\n",
    "        self.noise = self._ornstein_uhlenbeck_process(noise)\n",
    "        actions += self.noise\n",
    "\n",
    "    actions = tf.clip_by_value(actions, self.lower_bound, self.upper_bound)\n",
    "\n",
    "    return actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action_training(model, state, epsilon, n_actions=15):\n",
    "     if np.random.uniform() > epsilon:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _, action_idx = model(state).reshape(1,-1).max(1)\n",
    "\n",
    "        model.train()\n",
    "        return action_idx\n",
    "     else:\n",
    "        return torch.tensor([random.choices(range(n_actions), k=1)])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_rlp",
   "language": "python",
   "name": "env_rlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
